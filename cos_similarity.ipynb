{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# A Brief Primer on Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sources** - https://en.wikipedia.org/wiki/Cosine_similarity and Stackoverflow\n",
    "\n",
    "## Definition\n",
    "Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them. Below is a list of break-down definitions.\n",
    "\n",
    "##### Measure of Similarity \n",
    "A real-valued function that quantifies the similarity between two objects. For cosine similarity, the 2 objects are 2 non-zero vectors.This measure is usually the inverse of a distance metric: it takes on large values for similar vectors and either zero or a negative value for very dissimilar vectors. \n",
    "\n",
    "Example - Euclidean Distance\n",
    "\n",
    "##### Inner Product Space\n",
    "An inner product space is a vector space together with an inner product on it. An inner product in turn is a generalization of dot product. A vector space is simply a collection of vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Application in Information Retrieval\n",
    "For example, in information retrieval, each term assigned a different dimension and a document is characterised by a vector where the value in each dimension corresponds to the number of times the term appears in the document. \n",
    "Cosine similarity then gives a useful measure of how similar two documents are likely to be in terms of their subject matter.\n",
    "##### Advantages\n",
    "Low Complexity especially when dealing with sparse vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formula\n",
    "#### The cosine of two non-zero vectors can be derived by using the Euclidean dot product formula:\n",
    "$${\\text similarity = \\cos \\theta = \\displaystyle \\dfrac {\\mathbf {A} \\cdot \\mathbf {B}}{\\left\\|\\mathbf {A} \\right\\|\\left\\|\\mathbf {B} \\right\\|}}$$\n",
    "\n",
    "The resulting similarity ranges from âˆ’1 meaning exactly opposite, 1 meaning exactly the same, and 0 indicating decorrelation.  Any in-between values indicate intermediate similarity or dissimilarity. For text matching, Cosine similarity can be seen as a method of normalizing document length during comparison.\n",
    "\n",
    "##### Normalization\n",
    "In the simplest sense, this means adjusting values measured on different scales to a notionally common scale, often prior to averaging. In more complicated cases, normalization might mean more sophisticated adjustments, where the intention is to bring entire probability distributions of adjusted values into alignment.\n",
    "\n",
    "Example: In educational assessment, there may be an intention to align distributions to a normal distribution. This is a type of normalization.\n",
    "\n",
    "###### *Note*: To display Latex inside a Jupyter cell, use *$$* before and after the Latex lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Cosine Similarity vs. Cosine Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Cosine Distance\n",
    "The term \"cosine similarity\" is sometimes used to refer to a different definition of similarity. \n",
    "\n",
    "The normalized angle between the vectors is yet another formal distance metric and can be calculated from the similarity score defined above. This angular distance metric can then be used to compute a similarity function bounded between 0 and 1, inclusive.\n",
    "\n",
    "When the vector elements may be positive or negative:\n",
    "\n",
    "$${\\displaystyle {\\text{angular distance}}= 1 - {\\frac {\\cos ^{-1}({\\text{cosine similarity}})}{\\pi }}}$$\n",
    "\n",
    "When the vector elements are always positive:\n",
    "\n",
    "$${\\displaystyle {\\text{angular distance}}= 1 - {\\frac {2\\cdot \\cos ^{-1}({\\text{cosine similarity}})}{\\pi }}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider the following 2 lists\n",
    "data_I = [41, 5, 187, 10]\n",
    "data_II = [30, 4, 182, 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity using pure Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure Python: 0.9982020836071523\n"
     ]
    }
   ],
   "source": [
    "def dot(A,B): \n",
    "    return (sum(a*b for a,b in zip(A,B)))\n",
    "\n",
    "def cosine_similarity(a,b):\n",
    "    \"\"\"Here math.sqrt(var) is written as (var**0.5)\"\"\"\n",
    "    return dot(a,b) / ( (dot(a,a) **0.5) * (dot(b,b) ** 0.5) )\n",
    "\n",
    "print('Pure Python: '+ str(cosine_similarity(data_I, data_II)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity using Numpy Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy:\n",
      "Cosine similarity is 0.998202083607\n"
     ]
    }
   ],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "cos_similarity_numpy = dot(data_I, data_II)/(norm(data_I)*norm(data_II))\n",
    "print('Numpy:\\nCosine similarity is ' + str(cos_similarity_numpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity using Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scipy:\n",
      "Cosine distance is 0.00179791639285\n",
      "Cosine similarity is 0.998202083607\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "cos_distance= spatial.distance.cosine(data_I, data_II)\n",
    "print('Scipy:\\nCosine distance is ' + str(cos_distance))\n",
    "\n",
    "cos_similarity_scipy = 1 - cos_distance\n",
    "print('Cosine similarity is ' + str(cos_similarity_scipy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn:\n",
      "Cosine similarity is [[ 0.99820208]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cos_similarity_sklearn = cosine_similarity([data_I], [data_II])\n",
    "print('Sklearn:\\nCosine similarity is ' + str(cos_similarity_sklearn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
